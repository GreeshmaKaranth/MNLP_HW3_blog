const e=JSON.parse('{"key":"v-541b18b0","path":"/nlp/ERNIE-M/","title":"Understanding ERNIE-M - Enhanced Multilingual Representation by Aligning Cross-lingual Semantics with Monolingual Corpora","lang":"en-US","frontmatter":{"title":"Understanding ERNIE-M - Enhanced Multilingual Representation by Aligning Cross-lingual Semantics with Monolingual Corpora","author":"Anirudh Kannan, Greeshma Karanth","date":"2023-11-14T00:00:00.000Z","tag":["Multilingual NLP","11-737 MNLP Homework 3","Cross-Lingual Semantics"],"category":["MNLP"],"summary":"Ernie-M: An improved multilingual language model that uses knowledge learned from monolingual corpora to perform cross-lingual tasks better.\\nReading Time: About 10 minutes.\\n","head":[["meta",{"property":"og:url","content":"https://lileicc.github.io/blog/nlp/ERNIE-M/"}],["meta",{"property":"og:site_name","content":"MLNLP Blog"}],["meta",{"property":"og:title","content":"Understanding ERNIE-M - Enhanced Multilingual Representation by Aligning Cross-lingual Semantics with Monolingual Corpora"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:updated_time","content":"2023-11-17T02:22:09.000Z"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"article:author","content":"Anirudh Kannan, Greeshma Karanth"}],["meta",{"property":"article:tag","content":"Multilingual NLP"}],["meta",{"property":"article:tag","content":"11-737 MNLP Homework 3"}],["meta",{"property":"article:tag","content":"Cross-Lingual Semantics"}],["meta",{"property":"article:published_time","content":"2023-11-14T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2023-11-17T02:22:09.000Z"}]]},"excerpt":"<p>Ernie-M: An improved multilingual language model that uses knowledge learned from monolingual corpora to perform cross-lingual tasks better.</p>\\n<p>Reading Time: About 10 minutes.</p>\\n","headers":[{"level":2,"title":"Introduction","slug":"introduction","link":"#introduction","children":[]},{"level":2,"title":"Background","slug":"background","link":"#background","children":[]},{"level":2,"title":"ERNIE-M Methodology","slug":"ernie-m-methodology","link":"#ernie-m-methodology","children":[{"level":3,"title":"Cross-attention Masked Language Modeling (CAMLM)","slug":"cross-attention-masked-language-modeling-camlm","link":"#cross-attention-masked-language-modeling-camlm","children":[]},{"level":3,"title":"Back-translation Masked Language Modeling (BTMLM)","slug":"back-translation-masked-language-modeling-btmlm","link":"#back-translation-masked-language-modeling-btmlm","children":[]}]},{"level":2,"title":"Experiments and Results","slug":"experiments-and-results","link":"#experiments-and-results","children":[]},{"level":2,"title":"Conclusion","slug":"conclusion","link":"#conclusion","children":[]},{"level":2,"title":"References","slug":"references","link":"#references","children":[]}],"git":{"createdTime":1700014201000,"updatedTime":1700187729000,"contributors":[{"name":"Greeshma Karanth","email":"greeshmakaranth.13@gmail.com","commits":5}]},"readingTime":{"minutes":6.09,"words":1828},"filePathRelative":"nlp/ERNIE-M/README.md","localizedDate":"November 14, 2023"}');export{e as data};
